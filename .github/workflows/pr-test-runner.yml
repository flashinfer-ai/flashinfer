# PR Test Runner - Runs tests and updates check runs.
# Triggered by pr-test.yml via workflow_dispatch. Not visible on PR status.

name: PR Test Runner

on:
  workflow_dispatch:
    inputs:
      pr_head_sha:
        description: 'PR head SHA for check run updates'
        required: true
        type: string
      docker_tag:
        description: 'Docker image tag'
        required: true
        type: string
      aot_check_id:
        description: 'AOT Build check run ID'
        required: false
        type: string
      gpu_a10g_check_id:
        description: 'GPU A10G check run ID'
        required: false
        type: string
      gpu_t4_check_id:
        description: 'GPU T4 check run ID'
        required: false
        type: string
      summary_check_id:
        description: 'Test Results Summary check run ID'
        required: false
        type: string
      skip_aot:
        description: 'Skip AOT build tests'
        required: false
        type: string
        default: 'false'
      skip_gpu:
        description: 'Skip GPU tests'
        required: false
        type: string
        default: 'false'
      concurrency_key:
        description: 'Concurrency group key for cancelling outdated runs'
        required: false
        type: string

concurrency:
  group: ${{ inputs.concurrency_key || github.run_id }}
  cancel-in-progress: true

env:
  EXECUTOR_NUMBER: "0"

jobs:
  aot-build-import:
    name: AOT Build Import (${{ matrix.arch }}, ${{ matrix.cuda }})
    if: inputs.skip_aot != 'true'
    runs-on:
      - self-hosted
      - Linux
      - ${{ matrix.arch }}
      - cpu
      - spot
    timeout-minutes: 360
    strategy:
      fail-fast: true
      matrix:
        arch: [X64, ARM64]
        cuda: [cu126, cu128, cu129, cu130]
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-${{ matrix.cuda }}:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Start spot termination monitor
        run: ./scripts/task_monitor_spot.sh &

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run Test
        run: bash ci/bash.sh ${DOCKER_IMAGE} --no-gpu ./scripts/task_test_jit_cache_package_build_import.sh

  analyze-aot-failure:
    name: Analyze AOT Failure
    needs: aot-build-import
    if: "!cancelled() && inputs.skip_aot != 'true' && (needs.aot-build-import.result == 'failure' || needs.aot-build-import.result == 'cancelled')"
    runs-on: ubuntu-latest
    outputs:
      is_spot_termination: ${{ steps.analyze.outputs.is_spot_termination }}
      rerun_matrix: ${{ steps.matrix.outputs.rerun_matrix }}
    steps:
      - name: Analyze failure from job logs
        id: analyze
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          RUN_ID="${{ github.run_id }}"
          SPOT_TERMINATION=false
          FAILED_JOBS=$(gh api "/repos/${{ github.repository }}/actions/runs/${RUN_ID}/jobs?per_page=100" \
            --jq '.jobs[] | select(.name | startswith("AOT")) | select(.conclusion == "failure" or .conclusion == "cancelled") | .id')
          if [ -z "$FAILED_JOBS" ]; then
            echo "is_spot_termination=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          for JOB_ID in $FAILED_JOBS; do
            if ! gh api "/repos/${{ github.repository }}/actions/jobs/${JOB_ID}/logs" > job_log.zip 2>/dev/null; then
              continue
            fi
            if file job_log.zip | grep -q "Zip archive"; then
              unzip -p job_log.zip > job_log.txt 2>/dev/null || mv job_log.zip job_log.txt
            else
              mv job_log.zip job_log.txt
            fi
            if grep -q "FLASHINFER_SPOT_TERMINATION_DETECTED" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
            if grep -qiE "connection reset by peer|context canceled|grpc.*closing|The self-hosted runner.*lost" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
          done
          echo "is_spot_termination=$SPOT_TERMINATION" >> $GITHUB_OUTPUT

      - name: Build rerun matrix
        id: matrix
        if: steps.analyze.outputs.is_spot_termination == 'true'
        run: |
          MATRIX='{"include":['
          for arch in X64 ARM64; do
            for cuda in cu126 cu128 cu129 cu130; do
              MATRIX+='{"arch":"'$arch'","cuda":"'$cuda'"},'
            done
          done
          MATRIX="${MATRIX%,}]}"
          echo "rerun_matrix=$MATRIX" >> $GITHUB_OUTPUT

  aot-build-import-rerun:
    name: AOT Build Import Rerun (${{ matrix.arch }}, ${{ matrix.cuda }})
    needs: analyze-aot-failure
    if: |
      !cancelled() &&
      needs.analyze-aot-failure.outputs.is_spot_termination == 'true' &&
      needs.analyze-aot-failure.outputs.rerun_matrix != ''
    runs-on:
      - self-hosted
      - Linux
      - ${{ matrix.arch }}
      - cpu
      - on-demand
    timeout-minutes: 360
    strategy:
      fail-fast: true
      matrix: ${{ fromJSON(needs.analyze-aot-failure.outputs.rerun_matrix) }}
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-${{ matrix.cuda }}:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run Test
        run: bash ci/bash.sh ${DOCKER_IMAGE} --no-gpu ./scripts/task_test_jit_cache_package_build_import.sh

  gpu-tests-a10g:
    name: JIT Unittest ${{ matrix.shard }} (A10G)
    if: inputs.skip_gpu != 'true'
    runs-on: [self-hosted, Linux, X64, gpu, sm86, spot]
    timeout-minutes: 360
    strategy:
      fail-fast: true
      matrix:
        shard: [1, 2, 3, 4, 5]
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-cu129:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true
          nvidia-smi || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Start spot termination monitor
        run: ./scripts/task_monitor_spot.sh &

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run JIT Unittest Part ${{ matrix.shard }}
        run: bash ci/bash.sh ${DOCKER_IMAGE} ./scripts/task_jit_run_tests_part${{ matrix.shard }}.sh

  analyze-gpu-a10g-failure:
    name: Analyze GPU A10G Failure
    needs: gpu-tests-a10g
    if: "!cancelled() && inputs.skip_gpu != 'true' && (needs.gpu-tests-a10g.result == 'failure' || needs.gpu-tests-a10g.result == 'cancelled')"
    runs-on: ubuntu-latest
    outputs:
      is_spot_termination: ${{ steps.analyze.outputs.is_spot_termination }}
      rerun_matrix: ${{ steps.matrix.outputs.rerun_matrix }}
    steps:
      - name: Analyze failure from job logs
        id: analyze
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          RUN_ID="${{ github.run_id }}"
          SPOT_TERMINATION=false
          FAILED_JOBS=$(gh api "/repos/${{ github.repository }}/actions/runs/${RUN_ID}/jobs?per_page=100" \
            --jq '.jobs[] | select(.name | contains("A10G")) | select(.conclusion == "failure" or .conclusion == "cancelled") | .id')
          if [ -z "$FAILED_JOBS" ]; then
            echo "is_spot_termination=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          for JOB_ID in $FAILED_JOBS; do
            if ! gh api "/repos/${{ github.repository }}/actions/jobs/${JOB_ID}/logs" > job_log.zip 2>/dev/null; then
              continue
            fi
            if file job_log.zip | grep -q "Zip archive"; then
              unzip -p job_log.zip > job_log.txt 2>/dev/null || mv job_log.zip job_log.txt
            else
              mv job_log.zip job_log.txt
            fi
            if grep -q "FLASHINFER_SPOT_TERMINATION_DETECTED" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
            if grep -qiE "connection reset by peer|context canceled|grpc.*closing|The self-hosted runner.*lost" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
          done
          echo "is_spot_termination=$SPOT_TERMINATION" >> $GITHUB_OUTPUT

      - name: Build rerun matrix
        id: matrix
        if: steps.analyze.outputs.is_spot_termination == 'true'
        run: |
          echo 'rerun_matrix={"include":[{"shard":1},{"shard":2},{"shard":3},{"shard":4},{"shard":5}]}' >> $GITHUB_OUTPUT

  gpu-tests-a10g-rerun:
    name: JIT Rerun ${{ matrix.shard }} (A10G)
    needs: analyze-gpu-a10g-failure
    if: |
      !cancelled() &&
      needs.analyze-gpu-a10g-failure.outputs.is_spot_termination == 'true' &&
      needs.analyze-gpu-a10g-failure.outputs.rerun_matrix != ''
    runs-on: [self-hosted, Linux, X64, gpu, sm86, on-demand]
    timeout-minutes: 360
    strategy:
      fail-fast: true
      matrix: ${{ fromJSON(needs.analyze-gpu-a10g-failure.outputs.rerun_matrix) }}
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-cu129:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true
          nvidia-smi || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run JIT Unittest Part ${{ matrix.shard }}
        run: bash ci/bash.sh ${DOCKER_IMAGE} ./scripts/task_jit_run_tests_part${{ matrix.shard }}.sh

  gpu-tests-t4:
    name: JIT Unittest (T4)
    if: inputs.skip_gpu != 'true'
    runs-on: [self-hosted, Linux, X64, gpu, sm75, spot]
    timeout-minutes: 360
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-cu129:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true
          nvidia-smi || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Start spot termination monitor
        run: ./scripts/task_monitor_spot.sh &

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run JIT Unittest Part 3 (T4)
        run: bash ci/bash.sh ${DOCKER_IMAGE} ./scripts/task_jit_run_tests_part3.sh

  analyze-gpu-t4-failure:
    name: Analyze GPU T4 Failure
    needs: gpu-tests-t4
    if: "!cancelled() && inputs.skip_gpu != 'true' && (needs.gpu-tests-t4.result == 'failure' || needs.gpu-tests-t4.result == 'cancelled')"
    runs-on: ubuntu-latest
    outputs:
      is_spot_termination: ${{ steps.analyze.outputs.is_spot_termination }}
    steps:
      - name: Analyze failure from job logs
        id: analyze
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          RUN_ID="${{ github.run_id }}"
          SPOT_TERMINATION=false
          FAILED_JOBS=$(gh api "/repos/${{ github.repository }}/actions/runs/${RUN_ID}/jobs?per_page=100" \
            --jq '.jobs[] | select(.name | contains("T4")) | select(.conclusion == "failure" or .conclusion == "cancelled") | .id')
          if [ -z "$FAILED_JOBS" ]; then
            echo "is_spot_termination=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          for JOB_ID in $FAILED_JOBS; do
            if ! gh api "/repos/${{ github.repository }}/actions/jobs/${JOB_ID}/logs" > job_log.zip 2>/dev/null; then
              continue
            fi
            if file job_log.zip | grep -q "Zip archive"; then
              unzip -p job_log.zip > job_log.txt 2>/dev/null || mv job_log.zip job_log.txt
            else
              mv job_log.zip job_log.txt
            fi
            if grep -q "FLASHINFER_SPOT_TERMINATION_DETECTED" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
            if grep -qiE "connection reset by peer|context canceled|grpc.*closing|The self-hosted runner.*lost" job_log.txt; then
              SPOT_TERMINATION=true
              break
            fi
          done
          echo "is_spot_termination=$SPOT_TERMINATION" >> $GITHUB_OUTPUT

  gpu-tests-t4-rerun:
    name: JIT Rerun (T4)
    needs: analyze-gpu-t4-failure
    if: |
      !cancelled() &&
      needs.analyze-gpu-t4-failure.outputs.is_spot_termination == 'true'
    runs-on: [self-hosted, Linux, X64, gpu, sm75, on-demand]
    timeout-minutes: 360
    env:
      DOCKER_IMAGE: flashinfer/flashinfer-ci-cu129:${{ inputs.docker_tag }}
    steps:
      - name: Cleanup
        run: |
          docker stop $(docker ps -q) 2>/dev/null || true
          docker rm $(docker ps -aq) 2>/dev/null || true
          sudo rm -rf ${{ github.workspace }}/* || true
          sudo rm -rf ${{ github.workspace }}/.[!.]* || true
          rm -rf ~/.cache/flashinfer_jit || true
          docker system prune -f || true
          nvidia-smi || true

      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.pr_head_sha }}
          submodules: recursive

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: flashinfer
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      - name: Show Node Info
        run: ./scripts/task_show_node_info.sh
        env:
          NODE_NAME: ${{ runner.name }}
          WORKSPACE: ${{ github.workspace }}
          BUILD_NUMBER: ${{ github.run_number }}

      - name: Run JIT Unittest Part 3 (T4)
        run: bash ci/bash.sh ${DOCKER_IMAGE} ./scripts/task_jit_run_tests_part3.sh

  update-check-runs:
    name: Update Check Runs
    if: always()
    needs:
      - aot-build-import
      - analyze-aot-failure
      - aot-build-import-rerun
      - gpu-tests-a10g
      - analyze-gpu-a10g-failure
      - gpu-tests-a10g-rerun
      - gpu-tests-t4
      - analyze-gpu-t4-failure
      - gpu-tests-t4-rerun
    runs-on: ubuntu-latest
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.GH_APP_ID }}
          private-key: ${{ secrets.GH_APP_KEY }}
          owner: flashinfer-ai
          repositories: flashinfer

      - name: Update AOT Check Run
        if: inputs.aot_check_id != '' && inputs.skip_aot != 'true'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          REPO: ${{ github.repository }}
          CHECK_ID: ${{ inputs.aot_check_id }}
          AOT_SPOT: ${{ needs.aot-build-import.result }}
          AOT_SPOT_TERM: ${{ needs.analyze-aot-failure.outputs.is_spot_termination }}
          AOT_RERUN: ${{ needs.aot-build-import-rerun.result }}
        run: |
          if [ "$AOT_SPOT" == "success" ]; then
            CONCLUSION="success"
            TITLE="AOT Build Tests Passed"
            SUMMARY="All AOT build tests passed on spot instances."
          elif [ "$AOT_SPOT_TERM" == "true" ] && [ "$AOT_RERUN" == "success" ]; then
            CONCLUSION="success"
            TITLE="AOT Build Tests Passed (rerun)"
            SUMMARY="Spot instance was terminated. Rerun on on-demand instances passed."
          else
            CONCLUSION="failure"
            TITLE="AOT Build Tests Failed"
            SUMMARY="AOT build tests failed. Check the workflow logs for details."
          fi

          gh api -X PATCH "repos/${REPO}/check-runs/${CHECK_ID}" \
            -f status="completed" \
            -f conclusion="$CONCLUSION" \
            -F output[title]="$TITLE" \
            -F output[summary]="$SUMMARY"

      - name: Update GPU A10G Check Run
        if: inputs.gpu_a10g_check_id != '' && inputs.skip_gpu != 'true'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          REPO: ${{ github.repository }}
          CHECK_ID: ${{ inputs.gpu_a10g_check_id }}
          GPU_SPOT: ${{ needs.gpu-tests-a10g.result }}
          GPU_SPOT_TERM: ${{ needs.analyze-gpu-a10g-failure.outputs.is_spot_termination }}
          GPU_RERUN: ${{ needs.gpu-tests-a10g-rerun.result }}
        run: |
          if [ "$GPU_SPOT" == "success" ]; then
            CONCLUSION="success"
            TITLE="JIT Unittest (A10G) Passed"
            SUMMARY="All JIT unittest passed on A10G spot instances."
          elif [ "$GPU_SPOT_TERM" == "true" ] && [ "$GPU_RERUN" == "success" ]; then
            CONCLUSION="success"
            TITLE="JIT Unittest (A10G) Passed (rerun)"
            SUMMARY="Spot instance was terminated. Rerun on on-demand A10G instances passed."
          else
            CONCLUSION="failure"
            TITLE="JIT Unittest (A10G) Failed"
            SUMMARY="JIT unittest on A10G failed. Check the workflow logs for details."
          fi

          gh api -X PATCH "repos/${REPO}/check-runs/${CHECK_ID}" \
            -f status="completed" \
            -f conclusion="$CONCLUSION" \
            -F output[title]="$TITLE" \
            -F output[summary]="$SUMMARY"

      - name: Update GPU T4 Check Run
        if: inputs.gpu_t4_check_id != '' && inputs.skip_gpu != 'true'
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          REPO: ${{ github.repository }}
          CHECK_ID: ${{ inputs.gpu_t4_check_id }}
          GPU_SPOT: ${{ needs.gpu-tests-t4.result }}
          GPU_SPOT_TERM: ${{ needs.analyze-gpu-t4-failure.outputs.is_spot_termination }}
          GPU_RERUN: ${{ needs.gpu-tests-t4-rerun.result }}
        run: |
          if [ "$GPU_SPOT" == "success" ]; then
            CONCLUSION="success"
            TITLE="JIT Unittest (T4) Passed"
            SUMMARY="All JIT unittest passed on T4 spot instances."
          elif [ "$GPU_SPOT_TERM" == "true" ] && [ "$GPU_RERUN" == "success" ]; then
            CONCLUSION="success"
            TITLE="JIT Unittest (T4) Passed (rerun)"
            SUMMARY="Spot instance was terminated. Rerun on on-demand T4 instances passed."
          else
            CONCLUSION="failure"
            TITLE="JIT Unittest (T4) Failed"
            SUMMARY="JIT unittest on T4 failed. Check the workflow logs for details."
          fi

          gh api -X PATCH "repos/${REPO}/check-runs/${CHECK_ID}" \
            -f status="completed" \
            -f conclusion="$CONCLUSION" \
            -F output[title]="$TITLE" \
            -F output[summary]="$SUMMARY"

      - name: Update Test Results Summary
        if: inputs.summary_check_id != ''
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          REPO: ${{ github.repository }}
          CHECK_ID: ${{ inputs.summary_check_id }}
          AOT_SPOT: ${{ needs.aot-build-import.result }}
          AOT_RERUN: ${{ needs.aot-build-import-rerun.result }}
          AOT_SPOT_TERM: ${{ needs.analyze-aot-failure.outputs.is_spot_termination }}
          GPU_A10G_SPOT: ${{ needs.gpu-tests-a10g.result }}
          GPU_A10G_RERUN: ${{ needs.gpu-tests-a10g-rerun.result }}
          GPU_A10G_SPOT_TERM: ${{ needs.analyze-gpu-a10g-failure.outputs.is_spot_termination }}
          GPU_T4_SPOT: ${{ needs.gpu-tests-t4.result }}
          GPU_T4_RERUN: ${{ needs.gpu-tests-t4-rerun.result }}
          GPU_T4_SPOT_TERM: ${{ needs.analyze-gpu-t4-failure.outputs.is_spot_termination }}
          SKIP_AOT: ${{ inputs.skip_aot }}
          SKIP_GPU: ${{ inputs.skip_gpu }}
        run: |
          ALL_PASSED=true
          SUMMARY_LINES=""

          if [ "$SKIP_AOT" != "true" ]; then
            if [ "$AOT_SPOT" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- AOT Build Tests: Passed\n"
            elif [ "$AOT_SPOT_TERM" == "true" ] && [ "$AOT_RERUN" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- AOT Build Tests: Passed (rerun after spot termination)\n"
            else
              SUMMARY_LINES="${SUMMARY_LINES}- AOT Build Tests: Failed\n"
              ALL_PASSED=false
            fi
          else
            SUMMARY_LINES="${SUMMARY_LINES}- AOT Build Tests: Skipped\n"
          fi

          if [ "$SKIP_GPU" != "true" ]; then
            if [ "$GPU_A10G_SPOT" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (A10G): Passed\n"
            elif [ "$GPU_A10G_SPOT_TERM" == "true" ] && [ "$GPU_A10G_RERUN" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (A10G): Passed (rerun after spot termination)\n"
            else
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (A10G): Failed\n"
              ALL_PASSED=false
            fi

            if [ "$GPU_T4_SPOT" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (T4): Passed\n"
            elif [ "$GPU_T4_SPOT_TERM" == "true" ] && [ "$GPU_T4_RERUN" == "success" ]; then
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (T4): Passed (rerun after spot termination)\n"
            else
              SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (T4): Failed\n"
              ALL_PASSED=false
            fi
          else
            SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (A10G): Skipped\n"
            SUMMARY_LINES="${SUMMARY_LINES}- JIT Unittest (T4): Skipped\n"
          fi

          if [ "$ALL_PASSED" == "true" ]; then
            CONCLUSION="success"
            TITLE="All tests passed"
          else
            CONCLUSION="failure"
            TITLE="Some tests failed"
          fi

          SUMMARY=$(printf '%b' "$SUMMARY_LINES")

          gh api -X PATCH "repos/${REPO}/check-runs/${CHECK_ID}" \
            -f status="completed" \
            -f conclusion="$CONCLUSION" \
            -F output[title]="$TITLE" \
            -F output[summary]="$SUMMARY"

          echo "Updated Test Results Summary: $CONCLUSION"
