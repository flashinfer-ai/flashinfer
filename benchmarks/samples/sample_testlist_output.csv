routine,median_time,std_time,tflops,tb_per_sec,backend,page_size,batch_size,s_qo,s_kv,num_qo_heads,num_kv_heads,head_dim_qk,head_dim_vo,head_dim_ckv,head_dim_kpe,causal,q_dtype,kv_dtype,avg_actual_seq_len,random_actual_seq_len,m,n,k,group_size,tile_size,scale_major_mode,out_dtype,mma_sm,use_128x4_sf_layout,use_nvfp4,num_tokens,hidden_size,intermediate_size,num_experts,top_k,n_group,topk_group,routed_scaling_factor,local_expert_offset,local_num_experts,tile_tokens_dim,routing_method,use_shuffled_weight,weight_layout,use_routing_bias,use_routing_scales_on_input,input_dtype,weight_dtype,gated_act,cutlass_variant,quantized_input,tp_size,tp_rank,ep_size,ep_rank,refcheck,no_cuda_graph,use_cupti,allow_output_mismatch,random_seed,case_tag,generate_repro_command,repro_command
BatchPrefillWithPagedKVCacheWrapper,0.01244799979031086,0.0009464459008260536,13.963516944729905,0.3050282827732261,fa2,16,1,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithPagedKVCacheWrapper,0.01839040070772171,0.00021363710731210026,9.45155349045863,0.20646597430613514,cudnn,16,1,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithPagedKVCacheWrapper,0.008396799862384795,5.550615129103214e-05,20.70048814413847,0.45219512936224815,trtllm-gen,16,1,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithPagedKVCacheWrapper,0.4833280146121979,0.003473954933671819,250.42114497152383,0.9745931908746264,fa2,16,32,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,399,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 32 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithPagedKVCacheWrapper,0.3817088007926941,0.0008139816712432105,317.08871937101173,1.2340511694301386,cudnn,16,32,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,399,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 32 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithPagedKVCacheWrapper,0.7442896127700807,0.00045553586925676576,162.6188955741738,0.6328829314799427,trtllm-gen,16,32,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,399,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 fa3 cudnn trtllm-gen --page_size 16 --batch_size 32 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchPrefillWithRaggedKVCacheWrapper,0.016127999871969223,0.00017067009388203107,26.943492277380717,1.0463492146555617,fa2,0,1,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchPrefillWithRaggedKVCacheWrapper,0.012083200365304947,9.971927609146905e-05,35.962710777165306,1.3966101272685556,cutlass,0,1,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchPrefillWithRaggedKVCacheWrapper,0.018636800348758698,0.00019618687934467522,23.316483080151837,0.9054944885495858,cudnn,0,1,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,103,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 1 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchPrefillWithRaggedKVCacheWrapper,0.49769599735736847,0.0053031528422255855,217.96787873723878,1.7256503660070768,fa2,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchPrefillWithRaggedKVCacheWrapper,0.5328896045684814,0.0014588070313195434,203.57263468827725,1.6116833067056566,cutlass,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchPrefillWithRaggedKVCacheWrapper,0.3123199939727783,0.0005266243249355331,347.3416460473396,2.7499016924124846,cudnn,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 fa3 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag DeepSeek-R1
BatchDecodeWithPagedKVCacheWrapper,0.03481600061058998,0.00022415261777036224,0.07905882214290773,0.0108235292219457,fa2,16,1,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,84,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 1 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.010452799871563912,4.634408684090133e-05,0.2633277240376533,0.03605081936229778,fa2_tc,16,1,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,84,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 1 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.010683200135827065,8.551724418800796e-05,0.25764864132510307,0.035273325895698635,cudnn,16,1,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,84,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 1 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.005734400078654289,3.59118315932623e-05,0.4799999934162147,0.06571428481293416,trtllm-gen,16,1,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,84,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 1 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.006188799999654293,9.38182546863553e-05,0.444756980376447,0.06088934850391835,trtllm-gen-native,16,1,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,84,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 1 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.055296000093221664,7.235326722628814e-05,4.756740732721512,0.604074073055686,fa2,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.017208000272512437,9.39948911411913e-05,15.28525870726272,1.941125027372111,fa2_tc,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.013764800131320953,9.368704015807337e-05,19.108794424228098,2.426688341372557,cudnn,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.00963199995458126,3.5251792291711315e-05,27.30780079321905,3.467906993096757,trtllm-gen,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchDecodeWithPagedKVCacheWrapper,0.009657599776983262,6.567264399555296e-05,27.2354148105071,3.458714460254226,trtllm-gen-native,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,True,42,Llama-3.1-70B,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --allow_output_mismatch --generate_repro_command --case_tag Llama-3.1-70B
BatchMLAPagedAttentionWrapper,0.024420800060033797,0.00010761519902284579,91.55081939697266,0.9553665704090659,trtllm-gen-native,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends trtllm-gen-native fa2 fa3 --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1
BatchMLAPagedAttentionWrapper,0.04095999896526337,0.0004555166043636676,54.58359909057617,0.5696000143893066,fa2,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,DeepSeek-R1,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends trtllm-gen-native fa2 fa3 --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1
bmm_fp8,0.2860383987426758,0.0004968334033247884,13.13843316323707,0.02569322172234466,cudnn,,256,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 256 --m 1 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
bmm_fp8,0.28600159883499143,0.00047219507506758893,13.14012368919739,0.025696527676546826,cublas,,256,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 256 --m 1 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
bmm_fp8,0.2657311916351318,0.00010204157533447904,14.142473681298727,0.027656700573153076,cutlass,,256,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 256 --m 1 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
bmm_fp8,0.07516320049762726,0.000206792690088806,49.99915329734576,0.09814504905539344,cudnn,,64,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 64 --m 4 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
bmm_fp8,0.07495999932289124,0.0002273436657742046,50.13469074101705,0.09841110014187592,cublas,,64,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 64 --m 4 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
bmm_fp8,0.072297602891922,9.86900944781081e-05,51.980926526955464,0.10203513954712654,cutlass,,64,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --batch_size 64 --m 4 --n 1024 --k 7168 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command
gemm_fp8_nt_groupwise,0.01966080069541931,1.0062279270694632e-06,2.986666561025716,0.37520832006189414,cutlass,,,,,,,,,,,,,,,,4,1024,7168,,128,MN,torch.bfloat16,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine gemm_fp8_nt_groupwise --m 4 --n 1024 --k 7168 --mma_sm 1 --scale_major_mode MN --backends cutlass --refcheck -vv --generate_repro_command
gemm_fp8_nt_groupwise,0.019865599274635316,1.2664492914798042e-06,11.823505586357996,0.37690723025708733,cutlass,,,,,,,,,,,,,,,,16,1024,7168,,128,MN,torch.bfloat16,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine gemm_fp8_nt_groupwise --m 16 --n 1024 --k 7168 --mma_sm 1 --scale_major_mode MN --backends cutlass --refcheck -vv --generate_repro_command
group_gemm_fp8_nt_groupwise,0.02232320010662079,3.682025865219179e-05,5.260917406065297,0.6609174280359654,cutlass,,,,,,,,,,,,,,,,4,1024,7168,2,128,MN,torch.bfloat16,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine group_gemm_fp8_nt_groupwise --m 4 --n 1024 --k 7168 --mma_sm 1 --group_size 2 --scale_major_mode MN --refcheck -vv --generate_repro_command
group_gemm_fp8_nt_groupwise,0.02252800017595291,9.332681200911203e-05,20.852363473498134,0.6647272675354804,cutlass,,,,,,,,,,,,,,,,16,1024,7168,2,128,MN,torch.bfloat16,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine group_gemm_fp8_nt_groupwise --m 16 --n 1024 --k 7168 --mma_sm 1 --group_size 2 --scale_major_mode MN --refcheck -vv --generate_repro_command
mm_fp4,0.012697599828243256,1.7496054581842973e-06,1.1561290478966861,0.28947581036726805,cudnn,,,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 1 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.009216000139713288,3.619193125084151e-05,1.5928888647409136,0.39883332728707516,cutlass,,,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 1 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.01085439994931221,3.680557773573178e-05,1.3524528365043527,0.3386320770530395,trtllm,,,,,,,,,,,,,,,,1,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 1 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.012697599828243256,1.7233627387457594e-06,4.6245161915867445,0.2908064555465576,cudnn,,,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 4 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.009216000139713288,5.744219533265305e-07,6.3715554589636545,0.4006666605926154,cutlass,,,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 4 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.011059200018644333,0.00010158394987753556,5.309629620678304,0.33388888832599684,trtllm,,,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 4 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --refcheck -vv --generate_repro_command
mm_fp4,0.009216000139713288,3.6526144810097353e-05,6.3715554589636545,0.4006666605926154,cutlass_autotune,,,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 4 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --autotune --refcheck -vv --generate_repro_command
mm_fp4,0.01085439994931221,0.00010171082787792661,5.409811346017411,0.34018868083389336,trtllm_autotune,,,,,,,,,,,,,,,,4,1024,7168,,,,torch.bfloat16,,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,False,42,None,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 4 --n 1024 --k 7168 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --use_nvfp4 --autotune --refcheck -vv --generate_repro_command
trtllm_fp4_block_scale_moe,0.22354559898376464,0.0001550481673529622,230.55523251765356,1.817630057791967,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,2.5,0,256,8,deepseek_v3,True,0,True,False,torch.bfloat16,torch.bfloat16,swiglu,,,,,,,False,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp4_block_scale_moe,0.22620320320129395,0.00015420901713100778,227.84649740850875,0.9027731398581356,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,8,None,None,2.5,0,128,8,renormalize_naive,True,0,False,False,torch.bfloat16,torch.bfloat16,swiglu,,,,,,,False,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 8 --routing_method renormalize_naive --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.556544017791748,0.00016468714317887162,92.60652509840739,1.45451329296815,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,2.5,0,256,8,deepseek_v3,True,0,True,False,torch.bfloat16,torch.bfloat16,,,,,,,,False,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_per_tensor_scale_moe,0.12308800220489502,0.00022594891363694267,52.34020236412443,3.2989491154796857,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,2.5,0,128,8,llama4,,,True,True,torch.bfloat16,torch.bfloat16,,,,,,,,False,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_per_tensor_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routed_scaling_factor 2.5 --use_routing_bias --routing_method llama4 --use_routing_scales_on_input -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.10864640474319458,0.00013707306207295686,59.29741494187403,3.7398678857383114,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,2.5,0,128,8,renormalize,True,0,False,False,torch.bfloat16,torch.bfloat16,,,,,,,,False,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routing_method renormalize --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
cutlass_fused_moe,0.026214399933815004,0.00010491445634120407,0.24000000060594173,0.00812988283302598,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,,base,False,1,0,1,0,False,False,False,False,42,cutlass_moe_base,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant base --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_base
cutlass_fused_moe,0.025804799795150758,0.0001189026818394618,0.2438095257449853,0.004290674637235764,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,,fp8,False,1,0,1,0,False,False,False,False,42,cutlass_moe_fp8_scale,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant fp8 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_fp8_scale
cutlass_fused_moe,0.02990399897098541,0.00010532265873466246,0.21038845025724934,0.002195826720824563,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,,nvfp4,False,1,0,1,0,False,False,False,False,42,cutlass_moe_nvfp4_weights,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights
cutlass_fused_moe,0.02949439883232117,0.00010231710901612176,0.21331019614156588,0.0020180102784388863,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,,nvfp4,True,1,0,1,0,False,False,False,False,42,cutlass_moe_nvfp4_weights_quantized,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --quantized_input --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights_quantized
cutlass_fused_moe,0.025190401077270507,0.00010808926975429793,0.24975608688012632,0.031890242538648944,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,8,2,,,,,,,,False,0,,False,torch.float16,torch.float16,,base,False,2,0,4,0,False,False,False,False,42,cutlass_moe_nvfp4_ep_tp,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 8 --top_k 2 --cutlass_variant base --input_dtype float16 --tp_size 2 --tp_rank 0 --ep_size 4 --ep_rank 0 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_ep_tp
