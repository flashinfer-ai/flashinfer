routine,median_time,std_time,tflops,tb_per_sec,backend,page_size,batch_size,s_qo,s_kv,num_qo_heads,num_kv_heads,head_dim_qk,head_dim_vo,head_dim_ckv,head_dim_kpe,causal,q_dtype,kv_dtype,avg_actual_seq_len,random_actual_seq_len,m,n,k,group_size,tile_size,scale_major_mode,out_dtype,mma_sm,use_128x4_sf_layout,num_tokens,hidden_size,intermediate_size,num_experts,top_k,n_group,topk_group,routed_scaling_factor,local_expert_offset,local_num_experts,tile_tokens_dim,routing_method,use_shuffled_weight,weight_layout,use_routing_bias,use_routing_scales_on_input,input_dtype,weight_dtype,cutlass_variant,quantized_input,tp_size,tp_rank,ep_size,ep_rank,refcheck,no_cuda_graph,allow_output_mismatch,random_seed,case_tag,generate_repro_command,repro_command
BatchPrefillWithPagedKVCacheWrapper,0.19863999634981155,0.002165767961613125,218.4489383678,0.972820638093932,fa2,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.1608159989118576,0.0018192673810026121,269.828229862772,1.2016285028078233,cudnn,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.28673599660396576,0.001861886966389733,151.33327114116457,0.6739338286392443,trtllm-gen,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.22121599316596985,0.005262696546444167,196.15533081030054,0.8735403134031935,trtllm-gen-native,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithRaggedKVCacheWrapper,0.623551994562149,0.04805235735626027,173.97384940797858,1.377349904241865,fa2,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithRaggedKVCacheWrapper,0.6593759953975677,0.042450288209893425,164.5218229920418,1.3025182687795007,cutlass,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithRaggedKVCacheWrapper,0.40140798687934875,0.02878509167335827,270.2530700581361,2.1395919066706175,cudnn,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchDecodeWithPagedKVCacheWrapper,0.050702399015426634,5.358291864043217e-05,5.187698040086255,0.6588027519139062,fa2,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.016179199516773223,4.390078744968736e-05,16.257215675430302,2.064557023687774,fa2_tc,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.012294400110840797,2.9022786451878258e-05,21.3941903328874,2.7169182472389553,cudnn,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.010036800056695938,4.2086111493617856e-05,26.206433775127696,3.328040791020405,trtllm-gen,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.010139200091361999,3.394793422831141e-05,25.941764007999502,3.2944295111068262,trtllm-gen-native,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchMLAPagedAttentionWrapper,0.04095999896526337,0.00018861917453252353,54.58359909057617,0.5696000143893066,fa2,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchMLAPagedAttentionWrapper,0.03270399942994118,0.0009912135423119442,68.36302185058594,0.713393358814707,trtllm-gen-native,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithPagedKVCacheWrapper,0.217056006193161,0.0020098751951206587,199.91474588076713,0.4451410753131434,trtllm-gen-native,16,16,1024,1024,64,8,128,128,,,True,torch.float8_e4m3fn,torch.float8_e4m3fn,327,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype fp8_e4m3 --kv_dtype fp8_e4m3 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchMLAPagedAttentionWrapper,0.022272000089287758,0.0009335132358293922,100.38362884521484,0.5237701128427505,trtllm-gen-native,32,16,1,1024,128,,,,512,64,False,torch.float8_e4m3fn,torch.float8_e4m3fn,501,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype fp8_e4m3 --kv_dtype fp8_e4m3 --generate_repro_command --case_tag DeepSeek-R1-1k
gemm_fp8_nt_groupwise,0.5826559960842133,0.03992277071294015,1887.0682446681349,0.46071002067093136,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,,128,MN,torch.bfloat16,2,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,gemm_fp8_nt_groupwise_sample,True,python3 flashinfer_benchmark.py --routine gemm_fp8_nt_groupwise --m 8192 --n 4096 --k 16384 --mma_sm 2 --no_cuda_graph --refcheck -vv --backend cutlass trtllm --scale_major_mode MN --generate_repro_command --case_tag gemm_fp8_nt_groupwise_sample
group_gemm_fp8_nt_groupwise,1.4235039949417114,0.019968493175593464,1544.795984673049,0.3771474571955686,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,2,128,K,torch.bfloat16,2,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,group_gemm_fp8_nt_groupwise_sample,True,python3 flashinfer_benchmark.py --routine group_gemm_fp8_nt_groupwise --m 8192 --n 4096 --k 16384 --mma_sm 2 --group_size 2 --no_cuda_graph --scale_major_mode K --refcheck -vv --generate_repro_command --case_tag group_gemm_fp8_nt_groupwise_sample
bmm_fp8,0.38998879194259645,0.020104750197258048,2819.341607996366,0.6883158222647378,cudnn,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
bmm_fp8,0.3898000001907349,0.027221875225817732,2820.7070991226083,0.6886491941217305,cublas,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
bmm_fp8,0.7879528045654296,0.05200885894277077,1395.4028990129693,0.3406745358918382,cutlass,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,,,,,,torch.float8_e4m3fn,,,,,,,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
mm_fp4,0.23255040645599365,0.030370730682184946,4728.057217926491,0.7214442776377091,cudnn,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
mm_fp4,0.20704638957977295,0.007477970763357942,5310.4602790108975,0.8103119322221218,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
mm_fp4,0.44398319721221924,0.0008919232676501257,2476.47125990321,0.37787952574206696,trtllm,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
trtllm_fp4_block_scale_moe,0.21626880168914794,8.311584052718314e-05,238.31272541140726,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,2.5,0,256,8,deepseek_v3,True,0,True,False,torch.bfloat16,torch.bfloat16,,,,,,,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp4_block_scale_moe,0.21883279085159302,8.078179339545469e-05,235.5204965006953,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,8,None,None,2.5,0,128,8,renormalize_naive,True,0,False,False,torch.bfloat16,torch.bfloat16,,,,,,,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 8 --routing_method renormalize_naive --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.5575168132781982,7.711632183621058e-05,92.4449385641792,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,2.5,0,256,8,deepseek_v3,True,0,True,False,torch.bfloat16,torch.bfloat16,,,,,,,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_per_tensor_scale_moe,0.12294880151748658,0.0001322201474068978,52.39946111295532,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,2.5,0,128,8,llama4,,,True,True,torch.bfloat16,torch.bfloat16,,,,,,,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_per_tensor_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routed_scaling_factor 2.5 --use_routing_bias --routing_method llama4 --use_routing_scales_on_input -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.10900479555130005,8.790583920886092e-05,59.102454267418366,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,2.5,0,128,8,renormalize,True,0,False,False,torch.bfloat16,torch.bfloat16,,,,,,,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routing_method renormalize --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
cutlass_fused_moe,0.02621600031852722,6.311745177817219e-05,0.23998534954066728,0.008129386535343648,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,base,False,1,0,1,0,False,False,False,42,cutlass_moe_base,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant base --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_base
cutlass_fused_moe,0.025600001215934753,6.292568009991926e-05,0.24575998832702692,0.004324999794573533,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,fp8,False,1,0,1,0,False,False,False,42,cutlass_moe_fp8_scale,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant fp8 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_fp8_scale
cutlass_fused_moe,0.02961200028657913,6.105981586975942e-05,0.21246305346185745,0.002217479378782814,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,nvfp4,False,1,0,1,0,False,False,False,42,cutlass_moe_nvfp4_weights,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights
cutlass_fused_moe,0.02913359999656677,5.8260115013703634e-05,0.2159518906259924,0.0020430018949602552,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,,,,,False,0,,False,torch.float16,torch.float16,nvfp4,True,1,0,1,0,False,False,False,42,cutlass_moe_nvfp4_weights_quantized,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --quantized_input --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights_quantized
cutlass_fused_moe,0.0261135995388031,6.361011789217322e-05,0.24092641807772644,0.030762821448889387,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,8,2,,,,,,,,False,0,,False,torch.float16,torch.float16,base,False,2,0,4,0,False,False,False,42,cutlass_moe_nvfp4_ep_tp,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 8 --top_k 2 --cutlass_variant base --input_dtype float16 --tp_size 2 --tp_rank 0 --ep_size 4 --ep_rank 0 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_ep_tp
