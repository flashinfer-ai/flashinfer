routine,median_time,std_time,tflops,tb_per_sec,backend,page_size,batch_size,s_qo,s_kv,num_qo_heads,num_kv_heads,head_dim_qk,head_dim_vo,head_dim_ckv,head_dim_kpe,causal,q_dtype,kv_dtype,avg_actual_seq_len,random_actual_seq_len,m,n,k,group_size,tile_size,scale_major_mode,out_dtype,mma_sm,use_128x4_sf_layout,num_tokens,hidden_size,intermediate_size,num_experts,top_k,n_group,topk_group,routing_method,use_shuffled_weight,weight_layout,use_routing_scales_on_input,input_dtype,weight_dtype,refcheck,no_cuda_graph,allow_output_mismatch,random_seed,case_tag,generate_repro_command,repro_command
BatchPrefillWithPagedKVCacheWrapper,0.19865599274635315,0.0024102237727591236,218.43134818190168,0.972742303559566,fa2,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.16169600188732147,0.001588517792124741,268.35973563674366,1.195088844154977,cudnn,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.286655992269516,0.0015982545893287823,151.37550754285954,0.6741219203899055,trtllm-gen,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithPagedKVCacheWrapper,0.22118400037288666,0.004039887160107042,196.1837033729642,0.8736666651937816,trtllm-gen-native,16,16,1024,1024,64,8,128,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchPrefillWithRaggedKVCacheWrapper,0.6258240044116974,0.04396713473667261,173.3422496345082,1.3723495326890773,fa2,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithRaggedKVCacheWrapper,0.6584320068359375,0.042231680370607885,164.7576965787305,1.3043856785261059,cutlass,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithRaggedKVCacheWrapper,0.41571199893951416,0.04019125197832017,260.9540765643958,2.0659718319195357,cudnn,0,16,1024,1024,128,128,192,128,,,True,torch.bfloat16,torch.bfloat16,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithRaggedKVCacheWrapper --backends fa2 cutlass cudnn --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_qk 192 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchDecodeWithPagedKVCacheWrapper,0.050704801082611085,4.6526212712022124e-05,5.18745228033651,0.658771542078987,fa2,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.016148799657821657,4.872283017686517e-05,16.28781962581363,2.0684435195046427,fa2_tc,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.012299199774861335,3.543317473893297e-05,21.385841421781887,2.7158579916941457,cudnn,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.010036800056695938,4.2680324992316104e-05,26.206433775127696,3.328040791020405,trtllm-gen,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchDecodeWithPagedKVCacheWrapper,0.01013999991118908,3.3699857424897735e-05,25.93971778143296,3.2941696540984453,trtllm-gen-native,16,16,1,1024,64,8,128,128,,,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,False,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchDecodeWithPagedKVCacheWrapper --backends fa2 fa2_tc cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchMLAPagedAttentionWrapper,0.04095999896526337,0.00020574491851206112,54.58359909057617,0.5696000143893066,fa2,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchMLAPagedAttentionWrapper,0.032336000353097916,0.0009379787344345298,69.14102935791016,0.7215121148328667,trtllm-gen-native,32,16,1,1024,128,,,,512,64,False,torch.bfloat16,torch.bfloat16,501,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype bfloat16 --kv_dtype bfloat16 --generate_repro_command --case_tag DeepSeek-R1-1k
BatchPrefillWithPagedKVCacheWrapper,0.2170879989862442,0.0020239947435965887,199.88528395229062,0.44507547377652307,trtllm-gen-native,16,16,1024,1024,64,8,128,128,,,True,torch.float8_e4m3fn,torch.float8_e4m3fn,327,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,Llama-3.1-70B-1k,True,python3 flashinfer_benchmark.py --routine BatchPrefillWithPagedKVCacheWrapper --backends fa2 cudnn trtllm-gen trtllm-gen-native --page_size 16 --batch_size 16 --s_qo 1024 --s_kv 1024 --num_qo_heads 64 --num_kv_heads 8 --head_dim_qk 128 --head_dim_vo 128 --random_actual_seq_len -vv --refcheck --causal --no_cuda_graph --q_dtype fp8_e4m3 --kv_dtype fp8_e4m3 --generate_repro_command --case_tag Llama-3.1-70B-1k
BatchMLAPagedAttentionWrapper,0.022415999323129654,0.0009647645271830193,99.73876953125,0.5204054404107339,trtllm-gen-native,32,16,1,1024,128,,,,512,64,False,torch.float8_e4m3fn,torch.float8_e4m3fn,501,True,,,,,,,,,,,,,,,,,,,,,,,True,True,False,42,DeepSeek-R1-1k,True,python3 flashinfer_benchmark.py --routine BatchMLAPagedAttentionWrapper --backends fa2 trtllm-gen-native --page_size 32 --batch_size 16 --s_qo 1 --s_kv 1024 --num_qo_heads 128 --num_kv_heads 128 --head_dim_ckv 512 --head_dim_kpe 64 --random_actual_seq_len -vv --refcheck --no_cuda_graph --q_dtype fp8_e4m3 --kv_dtype fp8_e4m3 --generate_repro_command --case_tag DeepSeek-R1-1k
gemm_fp8_nt_groupwise,0.6563839912414551,0.032542899499746224,1675.1042719619552,0.4089610038969617,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,,128,MN,torch.bfloat16,2,,,,,,,,,,,,,,,True,True,False,42,gemm_fp8_nt_groupwise_sample,True,python3 flashinfer_benchmark.py --routine gemm_fp8_nt_groupwise --m 8192 --n 4096 --k 16384 --mma_sm 2 --no_cuda_graph --refcheck -vv --backend cutlass trtllm --scale_major_mode MN --generate_repro_command --case_tag gemm_fp8_nt_groupwise_sample
group_gemm_fp8_nt_groupwise,1.4219039678573608,0.021457935528368773,1546.5342985614316,0.3775718502347245,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,2,128,K,torch.bfloat16,2,,,,,,,,,,,,,,,True,True,False,42,group_gemm_fp8_nt_groupwise_sample,True,python3 flashinfer_benchmark.py --routine group_gemm_fp8_nt_groupwise --m 8192 --n 4096 --k 16384 --mma_sm 2 --group_size 2 --no_cuda_graph --scale_major_mode K --refcheck -vv --generate_repro_command --case_tag group_gemm_fp8_nt_groupwise_sample
bmm_fp8,0.39003920555114746,0.021096531926054967,2818.977200567127,0.6882268556072088,cudnn,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,torch.float8_e4m3fn,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
bmm_fp8,0.3900864005088806,0.02445260102093649,2818.636144048218,0.6881435898555219,cublas,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,torch.float8_e4m3fn,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
bmm_fp8,0.786620807647705,0.04733009309118012,1397.7657558588583,0.34125140523897907,cutlass,,1,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,,,,,,,,,,,,,torch.float8_e4m3fn,,True,False,False,42,bmm_fp8_sample,True,python3 flashinfer_benchmark.py --routine bmm_fp8 --m 8192 --n 4096 --k 16384 --input_dtype fp8_e4m3 --mat2_dtype fp8_e4m3 --out_dtype bfloat16 --backends cudnn cublas cutlass --refcheck -vv --generate_repro_command --case_tag bmm_fp8_sample
mm_fp4,0.23257439136505126,0.01881698895304303,4727.56962330472,0.7213698766028931,cudnn,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
mm_fp4,0.20720479488372803,0.011039332704091154,5306.400502908176,0.8096924595501979,cutlass,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
mm_fp4,0.4442023992538452,0.0008513396420848185,2475.2491873590034,0.37769305227035577,trtllm,,,,,,,,,,,,,,,,8192,4096,16384,,,,torch.bfloat16,,True,,,,,,,,,,,,,,True,False,False,42,mm_fp4_sample,True,python3 flashinfer_benchmark.py --routine mm_fp4 --m 8192 --n 4096 --k 16384 --out_dtype bfloat16 --backends cudnn cutlass trtllm --use_128x4_sf_layout --refcheck -vv --generate_repro_command --case_tag mm_fp4_sample
trtllm_fp4_block_scale_moe,0.21616640090942382,8.376282612674025e-05,238.4256171873615,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,deepseek_v3,True,0,,torch.bfloat16,torch.bfloat16,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp4_block_scale_moe,0.21893839836120604,8.080760021919183e-05,235.4068904211568,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,8,None,None,renormalize_naive,True,0,,torch.bfloat16,torch.bfloat16,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp4_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 8 --routing_method renormalize_naive --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.5565384149551391,7.01955953952648e-05,92.60745739564888,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,256,8,8,4,deepseek_v3,True,0,,torch.bfloat16,torch.bfloat16,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 256 --top_k 8 --n_group 8 --topk_group 4 --routed_scaling_factor 2.5 --use_routing_bias --routing_method deepseek_v3 --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_per_tensor_scale_moe,0.12334239482879639,0.00012788911914341145,52.232251148863696,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,llama4,,,True,torch.bfloat16,torch.bfloat16,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_per_tensor_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routed_scaling_factor 2.5 --use_routing_bias --routing_method llama4 --use_routing_scales_on_input -vv --generate_repro_command --case_tag trtllm_moe_sample
trtllm_fp8_block_scale_moe,0.10859359502792358,9.529012260960872e-05,59.32625162969693,-1,trtllm,,,,,,,,,,,,,,,,,,,,,,,,,1024,1024,1024,128,1,None,None,renormalize,True,0,,torch.bfloat16,torch.bfloat16,False,False,False,42,trtllm_moe_sample,True,python3 flashinfer_benchmark.py --routine trtllm_fp8_block_scale_moe --num_tokens 1024 --hidden_size 1024 --intermediate_size 1024 --num_experts 128 --top_k 1 --routing_method renormalize --use_shuffled_weight -vv --generate_repro_command --case_tag trtllm_moe_sample
cutlass_fused_moe,0.02621680051088333,5.008057458472196e-05,0.23997802467880244,0.008129138409224568,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,False,0,False,torch.float16,torch.float16,False,False,False,42,cutlass_moe_base,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant base --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_base
cutlass_fused_moe,0.025600001215934753,8.650642775303132e-05,0.24575998832702692,0.004324999794573533,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,False,0,False,torch.float16,torch.float16,False,False,False,42,cutlass_moe_fp8_scale,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant fp8 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_fp8_scale
cutlass_fused_moe,0.02959439903497696,5.061125185549973e-05,0.2125894157392508,0.0022187982233527765,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,False,0,False,torch.float16,torch.float16,False,False,False,42,cutlass_moe_nvfp4_weights,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights
cutlass_fused_moe,0.029155999422073364,6.688500757031226e-05,0.21578598314955644,0.002041432335704422,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,2,2,,,,False,0,False,torch.float16,torch.float16,False,False,False,42,cutlass_moe_nvfp4_weights_quantized,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 2 --top_k 2 --cutlass_variant nvfp4 --quantized_input --input_dtype float16 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_weights_quantized
cutlass_fused_moe,0.026111999154090883,7.127300684110125e-05,0.24094118427597827,0.030764706878988437,cutlass,,,,,,,,,,,,,,,,,,,,,,,,,32,128,128,8,2,,,,False,0,False,torch.float16,torch.float16,False,False,False,42,cutlass_moe_nvfp4_ep_tp,True,python3 flashinfer_benchmark.py --routine cutlass_fused_moe --num_tokens 32 --hidden_size 128 --intermediate_size 128 --num_experts 8 --top_k 2 --cutlass_variant base --input_dtype float16 --tp_size 2 --tp_rank 0 --ep_size 4 --ep_rank 0 -vv --generate_repro_command --case_tag cutlass_moe_nvfp4_ep_tp
